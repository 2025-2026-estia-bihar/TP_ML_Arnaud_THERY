# TP Machine Learning - BIHAR 2025 (Arnaud THERY)

Projet d'Ã©valuation des modules Machine Learning II, Deep Learning I & II pour l'annÃ©e 2024-2025.

## ğŸ“‹ Description du Projet

Ce repository contient **trois sous-projets indÃ©pendants** de Machine Learning/Deep Learning :

| Sous-Projet                 | Module | Description                                             | Status      |
| --------------------------- | ------ | ------------------------------------------------------- | ----------- |
| **ğŸŒ¡ï¸ Time Series**          | ML II  | PrÃ©diction de tempÃ©rature (ARIMA/SARIMA/RF)             | âœ… ComplÃ©tÃ© |
| **ğŸŒ½ Image Classification** | DL I   | Classification d'images de maÃ¯s (CNN/Transfer Learning) | âœ… ComplÃ©tÃ© |

## ğŸ—ï¸ Architecture & Flux de DonnÃ©es

### Time Series (ML II)

```
Open-Meteo API â†’ AgrÃ©gation 3h â†’ Feature Engineering â†’ [ARIMA/SARIMA/RF] â†’ PrÃ©dictions
                                                              â†“
                                                        Ã‰valuation (RMSE/MAE)
```

### Image Classification (DL I)

```
Kaggle Dataset â†’ PrÃ©traitement (224Ã—224) â†’ Augmentation â†’ [CNN/VGG16/ResNet] â†’ Classification
                                                                  â†“
                                                            LIME (ExplicabilitÃ©)
```

## ğŸ› ï¸ Technologies UtilisÃ©es

| **Technologie**         | Usage                                  |
| ----------------------- | -------------------------------------- |
| **Python 3.10+**        | Langage principal                      |
| **NumPy, Pandas**       | Manipulation de donnÃ©es                |
| **Matplotlib, Seaborn** | Visualisation                          |
| **Scikit-learn**        | ML classique (RF, GradientBoosting)    |
| **Statsmodels**         | ModÃ¨les statistiques (ARIMA/SARIMA)    |
| **PyTorch**             | Deep Learning (CNN, Transfer Learning) |
| **LIME**                | ExplicabilitÃ© des modÃ¨les              |
| **Jupyter Notebook**    | ExpÃ©rimentation interactive            |

## ğŸ“‚ Structure du Repository

```
TP_ML/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ bihar_time_series.ipynb       # âœ… ML II - PrÃ©diction tempÃ©rature
â”‚   â””â”€â”€ corn_classification.ipynb     # âœ… DL I - Classification images
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ corn_images/                  # Dataset images maÃ¯s
â”œâ”€â”€ model/
â”‚   â””â”€â”€ registry/                     # ModÃ¨les entraÃ®nÃ©s sÃ©rialisÃ©s
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ monitoring.py                 # Scripts de visualisation
â”‚   â””â”€â”€ output/                       # Graphiques gÃ©nÃ©rÃ©s
â”œâ”€â”€ api/                              # â³ FastAPI (Ã  venir pour MLOps)
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ requirements.txt                  # DÃ©pendances Python
â”œâ”€â”€ TP.md                            # Ã‰noncÃ© du TP
â””â”€â”€ README.md                        # Ce fichier
```

## ğŸš€ Installation & ExÃ©cution Locale

### 1. Cloner le repository

```bash
git clone https://github.com/2024-2025-estia-bihar/TP_ML_Arnaud_THERY.git
cd TP_ML_Arnaud_THERY
```

### 2. CrÃ©er un environnement virtuel

```bash
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Lancer Jupyter Notebook

```bash
jupyter notebook
```

Puis ouvrir le notebook souhaitÃ© dans `notebooks/`.

## ğŸ“Š Sous-Projets DÃ©taillÃ©s

### ğŸŒ¡ï¸ Time Series Forecasting (ML II)

**Objectif:** DÃ©velopper un modÃ¨le de prÃ©diction de tempÃ©rature Ã  2 mÃ¨tres du sol avec un horizon de 24 heures et un pas de temps de 3 heures.

**DonnÃ©es:** 
- **Source:** Open-Meteo Historical Weather API
- **Localisation:** Ajaccio, France (41.9276Â°N, 8.7381Â°E)
- **PÃ©riode:** 2015-2024 (10 ans d'historique)
- **Variables:** Temperature 2m (Â°C), Relative Humidity 2m (%)

**MÃ©thodologie (8 phases):**

1. **Acquisition:** TÃ©lÃ©chargement via API + interpolation linÃ©aire
2. **Transformation:** AgrÃ©gation horaire â†’ 3h (moyenne mobile)
3. **Analyse Exploratoire:** DÃ©composition saisonniÃ¨re (tendance, saisonnalitÃ©, rÃ©sidus)
4. **ExpÃ©rimentation Statistique:** ARIMA â†’ SARIMA â†’ SARIMAX (avec humiditÃ©)
5. **ExpÃ©rimentation ML:** Random Forest, Linear Regression, Gradient Boosting
6. **Feature Engineering:** Lags (1-8 periods), rolling means, encodage cyclique saisonnier
7. **Analyse RÃ©sidus:** ACF, PACF, test Ljung-Box, distribution normale
8. **Ã‰valuation & Comparaison:** MÃ©triques MAE/RMSE/MAPE, cross-validation

**Split Chronologique:**
- Train: 85% (2015-2023)
- Validation: 5% 
- Test: 10% (2024 + anomalies dÃ©tectÃ©es)

**RÃ©sultats Finaux:**

| ModÃ¨le                    | MAE (Â°C) | RMSE (Â°C) | MAPE (%) | InterprÃ©tabilitÃ© |
| ------------------------- | -------- | --------- | -------- | ---------------- |
| ARIMA(3,0,2)              | 1.65     | 2.12      | 12.3     | â˜…â˜…â˜…â˜…â˜…            |
| SARIMA(3,0,2)Ã—(0,0,1,8)   | 1.42     | 1.78      | 10.1     | â˜…â˜…â˜…â˜…â˜†            |
| SARIMAX(3,0,2)Ã—(1,0,1,8)  | 1.38     | 1.72      | 9.8      | â˜…â˜…â˜…â˜…â˜†            |
| RandomForest              | 1.18     | 1.23      | 8.2      | â˜…â˜…â˜…â˜†â˜†            |
| GradientBoosting          | 1.21     | 1.26      | 8.5      | â˜…â˜…â˜…â˜†â˜†            |
| LinearRegression          | 1.72     | 2.15      | 11.2     | â˜…â˜…â˜…â˜…â˜…            |

**Recommandations:**
- âœ… **Court-terme (<24h):** RandomForest (RMSE 1.23Â°C, meilleure accuracy)
- âœ… **Long-terme (avec explicabilitÃ©):** SARIMA (RMSE 1.78Â°C, modÃ¨le interprÃ©table)
- âœ… **Production:** RandomForest + monitoring (dÃ©tection anomalies saisonniÃ¨res)

**Analyses AvancÃ©es:**
- DÃ©tection et segmentation des anomalies (pÃ©riodes chaudes/froides/normales)
- Quantification de l'impact de l'humiditÃ© sur la prÃ©cision (via SARIMAX)
- Analyse rÃ©sidus pour validation hypothÃ¨ses statistiques
- Zoom prÃ©dictions test sur pÃ©riodes critiques

**Notebook:** `notebooks/bihar_time_series.ipynb`

---

### ğŸŒ½ Image Classification (DL I)

**Objectif:** Classifier des photos de champs de maÃ¯s en 4 classes.

**DonnÃ©es:** Labeled Corn Dataset (Kaggle)

- Classes: ground (sol), corn (maÃ¯s), weeds (herbes), corn/weeds (mixte)
- Photos smartphone 1-1.5m du sol

**MÃ©thodologie:**

1. Phase 1: Classification 3 classes (Chao/ground, Milho/corn, Ervas/weeds)
2. Analyse exploratoire (distribution, tailles, aspect ratios)
3. PrÃ©traitement: resize 224Ã—224, normalisation ImageNet
4. Augmentation: rotation Â±20Â°, zoom Â±15%, flip horizontal, transformations affines
5. **Baseline CNN** (PyTorch):
   - 3 blocs Conv2D avec BatchNorm, ReLU, MaxPool, Dropout(0.25)
   - Classifier: Dense(256) â†’ ReLU â†’ Dropout(0.5) â†’ Dense(3)
   - Accuracy: **70.67%** (test set)
   - Par classe: Chao 99% | Milho 75% | Ervas 38%
6. Transfer Learning: VGG16, ResNet50 (implÃ©mentÃ©s)
7. Phase 2: Extension 4 classes (ajout Milho_ervas/corn+weeds)
8. ExplicabilitÃ©: LIME (superpixels)

**RÃ©sultats 3 Classes:**

| ModÃ¨le       | Accuracy | Chao | Milho | Ervas | Notes                    |
| ------------ | -------- | ---- | ----- | ----- | ------------------------ |
| Baseline CNN | 70.67%   | 99%  | 75%   | 38%   | âœ… PyTorch, 5 epochs     |
| VGG16        | 89.00%   | TBD  | TBD   | TBD   | âœ… Transfer learning     |
| ResNet50     | 97.67%   | TBD  | TBD   | TBD   | âœ… Architecture profonde |

**Notebook:** `notebooks/corn_classification.ipynb`

## ğŸ“ Livrables Conformes au TP

âœ… **Notebooks Jupyter** structurÃ©s avec:

- Description synthÃ©tique du projet
- Chargement et EDA
- Split train/val/test
- PrÃ©traitement justifiÃ©
- ModÃ©lisation et Ã©valuation
- Analyse et interprÃ©tation
- RÃ©sultats exÃ©cutÃ©s (pas de rÃ©exÃ©cution nÃ©cessaire)

âœ… **Code commentÃ©** avec justifications des choix

âœ… **Visualisations** avec titres, axes, lÃ©gendes, commentaires

âœ… **MÃ©thodologie rigoureuse** (pas de data leakage, reproductibilitÃ©)

## ğŸ”¬ RÃ©sultats SynthÃ©tiques

### Time Series (ML II)

| ModÃ¨le              | MAE (Â°C) | RMSE (Â°C) | MAPE (%) | InterprÃ©tabilitÃ© |
| ------------------- | -------- | --------- | -------- | ---------------- |
| ARIMA(1,1,1)        | 1.65     | 2.12      | 12.3     | â˜…â˜…â˜…â˜…â˜…            |
| SARIMA              | 1.42     | 1.78      | 10.1     | â˜…â˜…â˜…â˜…â˜†            |
| SARIMAX (+humidity) | 1.38     | 1.72      | 9.8      | â˜…â˜…â˜…â˜…â˜†            |
| RandomForest        | 1.18     | 1.23      | 8.2      | â˜…â˜…â˜…â˜†â˜†            |

**Conclusion:** RandomForest optimal pour court-terme (<24h), SARIMA pour long-terme (explicabilitÃ©)

### Image Classification (DL I)

| ModÃ¨le       | Accuracy 3C | Accuracy 4C | Notes                               |
| ------------ | ----------- | ----------- | ----------------------------------- |
| Baseline CNN | 70.67%      | 68.75%      | âœ… CNN custom, early stopping       |
| VGG16        | 89.00%      | TBD         | âœ… Transfer learning, fine-tuning   |
| ResNet50     | 97.67%      | 87.00%      | âœ… Architecture rÃ©siduelle profonde |

**Recommandation:** ResNet50 pour 4 classes (meilleure accuracy et gÃ©nÃ©ralisation)

## ğŸ§ª Tests & Quality Assurance

- âœ… Notebooks exÃ©cutÃ©s end-to-end sans erreurs
- âœ… RÃ©sultats reproductibles (seed fixÃ©s)
- âœ… Code commentÃ© et structurÃ©
- âœ… Pas de data leakage (splits chronologiques/train-val-test)
- âœ… Visualisations annotÃ©es (confusion matrices, courbes d'apprentissage)
- âœ… GPU acceleration activÃ©e (CUDA)
- âœ… Tous les modÃ¨les sÃ©rialisÃ©s (checkpoint.pth)

## ğŸ“š Documentation

- **TP.md**: Ã‰noncÃ© officiel du projet
- **README.md**: Ce fichier (architecture, installation, rÃ©sultats)
- **Notebooks**: Documentation inline + markdown
- **Support de prÃ©sentation**: Slides de synthÃ¨se (Ã  crÃ©er)

## ğŸ‘¤ Auteur

**Arnaud THERY**  
Parcours BIHAR-CORSE 2025-2026  
Organisation: [2025-2026-estia-bihar](https://github.com/2025-2026-estia-bihar)

## ğŸ“œ Licence

Projet acadÃ©mique - ESTIA Ã‰cole SupÃ©rieure des Technologies Industrielles AvancÃ©es
